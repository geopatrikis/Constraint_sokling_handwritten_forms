{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras, convert_to_tensor, reshape\n",
    "from Lenet import LeNet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.read_csv('label_dict.csv')\n",
    "label_dict_inv = pd.read_csv('label_dict_inv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_keras(img):\n",
    "#     cv2.imshow(\"input\",img)\n",
    "#     cv2.waitKey(0)\n",
    "#     print(f\"Img shape before: {img.shape}\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_inv = cv2.bitwise_not(gray)\n",
    "    _, binary = cv2.threshold(gray_inv, 35, 255, cv2.THRESH_BINARY)\n",
    "    # get the indices of the black pixels\n",
    "    y, x = np.nonzero(binary)\n",
    "    # get the maximum and minimum x and y coordinates\n",
    "    max_x = np.max(x)\n",
    "    min_x = np.min(x)\n",
    "    max_y = np.max(y)\n",
    "    min_y = np.min(y)\n",
    "    nonzero_indices = np.nonzero(binary)\n",
    "    zero_indices = np.where(binary == 0)\n",
    "    darkened_gray = gray.astype('float32')\n",
    "    darkened_gray[zero_indices] = 229+0.1*darkened_gray[zero_indices]\n",
    "    darkened_gray[nonzero_indices] *= 0.1\n",
    "    darkened_gray = darkened_gray.astype('uint8')\n",
    "    cropped = darkened_gray[min_y:max_y, min_x:max_x]\n",
    "    # _, thresh_img = cv2.threshold(gray_roi, 155, 255, cv2.THRESH_BINARY)\n",
    "    inverted_img = cv2.bitwise_not(cropped)\n",
    "    aspect_ratio = inverted_img.shape[1] / inverted_img.shape[0]\n",
    "    # resize the image while keeping the aspect ratio\n",
    "    new_height = 20\n",
    "    new_width = int(new_height * aspect_ratio)\n",
    "    if new_width > new_height:\n",
    "        new_width = 20\n",
    "        aspect_ratio = inverted_img.shape[0] / inverted_img.shape[1]\n",
    "        new_height = int(new_width * aspect_ratio)\n",
    "    resized_img = cv2.resize(inverted_img, (new_width, new_height))\n",
    "    # pad the resized image with black pixels to make it 28x28\n",
    "    pad_width = (\n",
    "        ((28 - new_height) // 2, (28 - new_height + 1) // 2),  # no padding on top and bottom\n",
    "        ((28 - new_width) // 2, (28 - new_width + 1) // 2))  # pad equally on both sides to make the width 28\n",
    "    padded_img = np.pad(resized_img, pad_width, mode='constant', constant_values=0)\n",
    "    # img_brighter = cv2.add(inverted_img, 50)\n",
    "    normalized_img = (cv2.resize(padded_img, (28, 28)))\n",
    "#     cv2.imshow(\"preprocessed image\",normalized_img)\n",
    "#     cv2.waitKey(0)\n",
    "    img_tensor = convert_to_tensor(normalized_img)\n",
    "    img_tensor /= 255\n",
    "    img_tensor = reshape(img_tensor, [1, 28, 28, 1])\n",
    "    img_tensor = np.array(img_tensor)\n",
    "#     print(f\"Img shape after: {img_tensor.shape}\")\n",
    "#     print(f\"Tensor type: {type(img_tensor)}\")\n",
    "#     print(f\"Tensor: {img_tensor}\")\n",
    "#     cv2.destroyAllWindows()\n",
    "#     normalized_tensor = 2 * (img_tensor - img_tensor.min()) / (img_tensor.max() - img_tensor.min()) - 1\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "def keras_preprocessing(img):\n",
    "    RGB = 1\n",
    "    img = img.reshape(img.shape[0], img.shape[1], img.shape[2], RGB)\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_characters(img_name, model):\n",
    "    img = cv2.imread(img_name)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to get a binary image\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 9, 5)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.CHAIN_APPROX_SIMPLE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    fields_points_sorted = []\n",
    "    # Loop through the contours\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        threshold_value = 200\n",
    "        black_found = False\n",
    "        character = img[max((y + 3), 0):y + h - 3, max((x + 3), 0):x + w - 3]\n",
    "        # Iterate over all pixels and check if their intensity values are above the threshold\n",
    "        for row in range(character.shape[0]):\n",
    "            for col in range(character.shape[1]):\n",
    "                pixel_intensity = character[row, col]\n",
    "                if (pixel_intensity < threshold_value).any():\n",
    "                    black_found = True\n",
    "                    break\n",
    "            if black_found:\n",
    "                break\n",
    "        # Get the bounding rectangle of the contour\n",
    "        if 30 < w < 100 and 40 < h < 100 and black_found:\n",
    "            fields_points_sorted.append([max((y + 3), 0), y + h - 3, max((x + 3), 0), x + w - 3])\n",
    "            # cv2.imwrite(\"C:/Users/30698/Desktop/KULeuven/Capita Selecta/test.jpeg\", character)\n",
    "            # show_one_prediction(character,model)\n",
    "            #cv2.rectangle(img, (x + 3, y + 3), (x + w - 3, y + h - 3), (0, 255, 0), 2)\n",
    "    fields_points_sorted.sort(key=lambda r: r[2])\n",
    "    characters_sorted = []\n",
    "    for field_points in fields_points_sorted:\n",
    "        characters_sorted.append(img[field_points[0]:field_points[1], field_points[2]:field_points[3]])\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "#     cv2.imshow('image', characters_sorted[4])\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    return characters_sorted\n",
    "\n",
    "\n",
    "def show_one_prediction(img, model, i=0):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_inv = cv2.bitwise_not(gray)\n",
    "    _, binary = cv2.threshold(gray_inv, 25, 255, cv2.THRESH_BINARY)\n",
    "    # get the indices of the black pixels\n",
    "    y, x = np.nonzero(binary)\n",
    "\n",
    "    # get the maximum and minimum x and y coordinates\n",
    "    max_x = np.max(x)\n",
    "    min_x = np.min(x)\n",
    "    max_y = np.max(y)\n",
    "    min_y = np.min(y)\n",
    "    nonzero_indices = np.nonzero(binary)\n",
    "    darkened_gray = gray.astype('float32')\n",
    "    darkened_gray[nonzero_indices] *= 0.3\n",
    "    darkened_gray[not nonzero_indices] *= 1.1\n",
    "    darkened_gray = darkened_gray.astype('uint8')\n",
    "    cropped = darkened_gray[min_y:max_y, min_x:max_x]\n",
    "    cv2.imshow(\"bin\", cropped)\n",
    "    cv2.waitKey(0)\n",
    "    # _, thresh_img = cv2.threshold(gray_roi, 155, 255, cv2.THRESH_BINARY)\n",
    "    inverted_img = cv2.bitwise_not(cropped)\n",
    "    aspect_ratio = inverted_img.shape[1] / inverted_img.shape[0]\n",
    "\n",
    "    # resize the image while keeping the aspect ratio\n",
    "    new_height = 24\n",
    "    new_width = int(new_height * aspect_ratio)\n",
    "    if new_width > new_height:\n",
    "        return\n",
    "    resized_img = cv2.resize(inverted_img, (new_width, new_height))\n",
    "\n",
    "    # pad the resized image with black pixels to make it 28x28\n",
    "    pad_width = (\n",
    "        ((28 - new_height) // 2, (28 - new_height + 1) // 2),  # no padding on top and bottom\n",
    "        ((28 - new_width) // 2, (28 - new_width + 1) // 2))  # pad equally on both sides to make the width 28\n",
    "    padded_img = np.pad(resized_img, pad_width, mode='constant', constant_values=0)\n",
    "    # img_brighter = cv2.add(inverted_img, 50)\n",
    "    normalized_img = (cv2.resize(padded_img, (28, 28)))\n",
    "    # Turn off gradients to speed up this part\n",
    "    img_tensor = torch.from_numpy(normalized_img).unsqueeze(0)\n",
    "    normalized_tensor = 2 * (img_tensor - img_tensor.min()) / (img_tensor.max() - img_tensor.min()) - 1\n",
    "    # Define a transform to normalize the data\n",
    "    # Apply the transform to the tensor\n",
    "    print(normalized_tensor)\n",
    "    with torch.no_grad():\n",
    "        logps = model(normalized_tensor)\n",
    "\n",
    "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    # print((\"pred:\", probab.index(max(probab))))\n",
    "    # print((\"pred:\", ))\n",
    "    view_classify(img_tensor, ps)\n",
    "    cv2.imshow(\"actual\", img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "def view_classify(img, ps):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6, 9), ncols=2)\n",
    "    ax1.imshow(img.numpy().squeeze(), cmap='gray_r')\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [\n",
    "    ['MICHELLE', 'RODRIGUEZ', '12/02/1950', 'RFMR12025033445', 'DE1202507171'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['LAURA', 'MENDOZA', '16/10/1952', 'RFLM16105293143', 'BR1610522746'],\n",
    "    ['ANGELA', 'FITZGERALD', '04/07/1956', 'RFAF04075656622', 'BE0407563203'],\n",
    "    ['DAVID', 'LOPEZ', '17/01/1963', 'RFDL17016329220', 'BR1701638007'],\n",
    "    ['HECTOR', 'COOK', '09/02/1964', 'RFHC09026495520', 'IT0902647355'],\n",
    "    ['TIMOTHY', 'GREEN', '19/08/1968', 'RFTG19086827450', 'BR1908688556'],\n",
    "    ['ELIZABETH', 'RIVERA', '08/07/1970', 'RFER08077010123', 'BR0807708065'],\n",
    "    ['DEREK', 'CHURCH', '13/01/1972', 'RFDC13017297192', 'BL1301728110'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['KENNETH', 'STONE', '19/01/1977', 'RFKS19017711799', 'DE1901777829'],\n",
    "    ['EDWIN', 'ALLEN', '22/09/1977', 'RFEA22097775609', 'DE2209776709'],\n",
    "    ['ANGEL', 'SCHWARTZ', '18/05/1982', 'RFAS18058263146', 'BR1805822377'],\n",
    "    ['JARED', 'MURRAY', '26/01/1985', 'RFJM26018598155', 'BR2601853435'],\n",
    "    ['MELISSA', 'MENDOZA', '11/06/1987', 'RFMM11068724346', 'BL1106877773'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343']\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "true_labels=[\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['TIMOTHY', 'GREEN', '19/08/1968', 'RFTG19086827450', 'BR1908688556'],\n",
    "    ['LAURA', 'MENDOZA', '16/10/1952', 'RFLM16105293143', 'BR1610522746'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['ELIZABETH', 'RIVERA', '08/07/1970', 'RFER08077010123', 'BR0807708065'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['KENNETH', 'STONE', '19/01/1977', 'RFKS19017711799', 'DE1901777829'],\n",
    "    ['MICHELLE', 'RODRIGUEZ', '12/02/1950', 'RFMR12025033445', 'DE1202507171'],\n",
    "    ['DEREK', 'CHURCH', '13/01/1972', 'RFDC13017297192', 'BL1301728110'],\n",
    "    ['DAVID', 'LOPEZ', '17/01/1963', 'RFDL17016329220', 'BR1701638007'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['EDWIN', 'ALLEN', '22/09/1977', 'RFEA22097775609', 'DE2209776709'],\n",
    "    ['ELIZABETH', 'RIVERA', '08/07/1970', 'RFER08077010123', 'BR0807708065'],\n",
    "    ['MELISSA', 'MENDOZA', '11/06/1987', 'RFMM11068724346', 'BL1106877773'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['ANGEL', 'SCHWARTZ', '18/05/1982', 'RFAS18058263146', 'BR1805822377'],\n",
    "    ['HECTOR', 'COOK', '09/02/1964', 'RFHC09026495520', 'IT0902647355'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['JARED', 'MURRAY', '26/01/1985', 'RFJM26018598155', 'BR2601853435'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793'],\n",
    "    ['HECTOR', 'COOK', '09/02/1964', 'RFHC09026495520', 'IT0902647355'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['TIMOTHY', 'GREEN', '19/08/1968', 'RFTG19086827450', 'BR1908688556'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LAURA', 'MENDOZA', '16/10/1952', 'RFLM16105293143', 'BR1610522746'],\n",
    "    ['ANGELA', 'FITZGERALD', '04/07/1956', 'RFAF04075656622', 'BE0407563203'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793'],\n",
    "    ['KENNETH', 'STONE', '19/01/1977', 'RFKS19017711799', 'DE1901777829'],\n",
    "    ['JARED', 'MURRAY', '26/01/1985', 'RFJM26018598155', 'BR2601853435'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793']\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_date(model, characters_for_recognition, labels):\n",
    "    i=0\n",
    "    correct_fields=0\n",
    "    for char in labels:\n",
    "        if char != '/':\n",
    "            processed_input = preprocess_keras(characters_for_recognition[i])\n",
    "            argmax = str(np.argmax(model.predict(processed_input)))\n",
    "            pred = str(label_dict_inv[argmax].get(0))\n",
    "            print(f\"Prediction: {pred}\")\n",
    "            # if int(probab.index(max(probab))) == int(char):\n",
    "            if pred == char:\n",
    "                correct_fields+=1\n",
    "        i += 1\n",
    "    return correct_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# model_digits = LeNet()\n",
    "# model_digits.load_state_dict(torch.load('saved_models/digits_model_nn3'))\n",
    "model_digits = keras.models.load_model('./alphanum_model')\n",
    "\n",
    "print(\"Model successfully loaded\")\n",
    "\n",
    "# extract_characters('C:/Users/30698/Desktop/KULeuven/Capita Selecta/formes/fields/0001_DATE.jpg')\n",
    "# dir_path = 'C:/Users/30698/Desktop/KULeuven/Capita Selecta/formes/fione\n",
    "\n",
    "# Define the allowed image extensions\n",
    "img_extensions = [\"DATE.jpg\", \"DATE.jpeg\", \"DATE.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220 files in './Forms 24022023/fields'\n",
      "Checking for 0017_DATE.jpg:\n",
      "17\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: |\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: Q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: A\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 4\n",
      "Checking for 0011_DATE.jpg:\n",
      "11\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 7\n",
      "Checking for 0028_DATE.jpg:\n",
      "28\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: I\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction: g\n",
      "Checking for 0033_DATE.jpg:\n",
      "33\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: G\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 6\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 8\n",
      "Checking for 0024_DATE.jpg:\n",
      "24\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: \\\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 8\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: S\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: \\\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 2\n",
      "Checking for 0030_DATE.jpg:\n",
      "30\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: b\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 4\n",
      "Checking for 0012_DATE.jpg:\n",
      "12\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: S\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction: O\n",
      "Checking for 0009_DATE.jpg:\n",
      "9\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 8\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: Y\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: a\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: Y\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "Checking for 0040_DATE.jpg:\n",
      "40\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: |\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: Y\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: )\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "Checking for 0037_DATE.jpg:\n",
      "37\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: \\\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: G\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: A\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: l\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: S\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction: 7\n",
      "Checking for 0026_DATE.jpg:\n",
      "26\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: S\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: \\\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: \\\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Prediction: 3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: F\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: G\n",
      "Checking for 0042_DATE.jpg:\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: Z\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction: 6\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: |\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: |\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: S\n",
      "Checking for 0035_DATE.jpg:\n",
      "35\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: S\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: !\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: |\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 7\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 6\n",
      "Checking for 0016_DATE.jpg:\n",
      "16\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: )\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: J\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: !\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: \\\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 2\n",
      "Checking for 0027_DATE.jpg:\n",
      "27\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: b\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: S\n",
      "Checking for 0023_DATE.jpg:\n",
      "23\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: l\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 7\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: Q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: L\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "Checking for 0019_DATE.jpg:\n",
      "19\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: I\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: l\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 6\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: |\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 8\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 7\n",
      "Checking for 0008_DATE.jpg:\n",
      "8\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 5\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: b\n",
      "Checking for 0013_DATE.jpg:\n",
      "13\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 2\n",
      "Checking for 0014_DATE.jpg:\n",
      "14\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: L\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: T\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: D\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: A\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: l\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: G\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 3\n",
      "Checking for 0020_DATE.jpg:\n",
      "20\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 4\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: #\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 2\n",
      "Checking for 0021_DATE.jpg:\n",
      "21\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 8\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: G\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 7\n",
      "Checking for 0010_DATE.jpg:\n",
      "10\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: A\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: D\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: 3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: A\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: g\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 9\n",
      "Checking for 0043_DATE.jpg:\n",
      "43\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 2\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 8\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: O\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction: s\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Prediction: q\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction: 9\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(fields_dir_path):\n",
    "        # Iterate over all files in the current directory\n",
    "        correct=0\n",
    "        print(f\"Found {len(files)} files in '{fields_dir_path}'\")\n",
    "        for file in files:\n",
    "            # Check if the file has an image extension            \n",
    "            if any(file.endswith(ext) for ext in img_extensions):\n",
    "                print(f\"Checking for {file}:\")\n",
    "                # Add the full path of the image to the list\n",
    "                img_path = os.path.join(root, file)\n",
    "                characters_of_date = extract_characters(img_path, model_digits)\n",
    "                file_index = int(file[:4])\n",
    "                print(file_index)\n",
    "                correct += predict_date(model_digits, characters_of_date, true_labels[file_index-1][2])                \n",
    "        print(\"Accuracy:\", correct/(44*8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
