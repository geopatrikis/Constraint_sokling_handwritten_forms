{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 16:43:00.849804: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-03 16:43:01.362109: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-03 16:43:01.362161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-03 16:43:01.362167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras, convert_to_tensor\n",
    "from Lenet import LeNet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.read_csv('label_dict.csv')\n",
    "label_dict_inv = pd.read_csv('label_dict_inv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pytorch(img):\n",
    "    #cv2.imshow(\"input\",img)\n",
    "    #cv2.waitKey(0)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_inv = cv2.bitwise_not(gray)\n",
    "    _, binary = cv2.threshold(gray_inv, 35, 255, cv2.THRESH_BINARY)\n",
    "    # get the indices of the black pixels\n",
    "    y, x = np.nonzero(binary)\n",
    "    # get the maximum and minimum x and y coordinates\n",
    "    max_x = np.max(x)\n",
    "    min_x = np.min(x)\n",
    "    max_y = np.max(y)\n",
    "    min_y = np.min(y)\n",
    "    nonzero_indices = np.nonzero(binary)\n",
    "    zero_indices = np.where(binary == 0)\n",
    "    darkened_gray = gray.astype('float32')\n",
    "    darkened_gray[zero_indices] = 229+0.1*darkened_gray[zero_indices]\n",
    "    darkened_gray[nonzero_indices] *= 0.1\n",
    "    darkened_gray = darkened_gray.astype('uint8')\n",
    "    cropped = darkened_gray[min_y:max_y, min_x:max_x]\n",
    "    # _, thresh_img = cv2.threshold(gray_roi, 155, 255, cv2.THRESH_BINARY)\n",
    "    inverted_img = cv2.bitwise_not(cropped)\n",
    "    aspect_ratio = inverted_img.shape[1] / inverted_img.shape[0]\n",
    "    # resize the image while keeping the aspect ratio\n",
    "    new_height = 20\n",
    "    new_width = int(new_height * aspect_ratio)\n",
    "    if new_width > new_height:\n",
    "        new_width = 20\n",
    "        aspect_ratio = inverted_img.shape[0] / inverted_img.shape[1]\n",
    "        new_height = int(new_width * aspect_ratio)\n",
    "    resized_img = cv2.resize(inverted_img, (new_width, new_height))\n",
    "    # pad the resized image with black pixels to make it 28x28\n",
    "    pad_width = (\n",
    "        ((28 - new_height) // 2, (28 - new_height + 1) // 2),  # no padding on top and bottom\n",
    "        ((28 - new_width) // 2, (28 - new_width + 1) // 2))  # pad equally on both sides to make the width 28\n",
    "    padded_img = np.pad(resized_img, pad_width, mode='constant', constant_values=0)\n",
    "    # img_brighter = cv2.add(inverted_img, 50)\n",
    "    normalized_img = (cv2.resize(padded_img, (28, 28)))\n",
    "    # Turn off gradients to speed up this part\n",
    "    img_tensor = torch.from_numpy(normalized_img).unsqueeze(0)\n",
    "    normalized_tensor = 2 * (img_tensor - img_tensor.min()) / (img_tensor.max() - img_tensor.min()) - 1\n",
    "    # Define a transform to normalize the data\n",
    "    # Apply the transform to the tensor\n",
    "    return normalized_tensor\n",
    "\n",
    "def preprocess_keras(img):\n",
    "#     cv2.imshow(\"input\",img)\n",
    "#     cv2.waitKey(0)\n",
    "    print(f\"Img shape before: {img.shape}\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_inv = cv2.bitwise_not(gray)\n",
    "    _, binary = cv2.threshold(gray_inv, 35, 255, cv2.THRESH_BINARY)\n",
    "    # get the indices of the black pixels\n",
    "    y, x = np.nonzero(binary)\n",
    "    # get the maximum and minimum x and y coordinates\n",
    "    max_x = np.max(x)\n",
    "    min_x = np.min(x)\n",
    "    max_y = np.max(y)\n",
    "    min_y = np.min(y)\n",
    "    nonzero_indices = np.nonzero(binary)\n",
    "    zero_indices = np.where(binary == 0)\n",
    "    darkened_gray = gray.astype('float32')\n",
    "    darkened_gray[zero_indices] = 229+0.1*darkened_gray[zero_indices]\n",
    "    darkened_gray[nonzero_indices] *= 0.1\n",
    "    darkened_gray = darkened_gray.astype('uint8')\n",
    "    cropped = darkened_gray[min_y:max_y, min_x:max_x]\n",
    "    # _, thresh_img = cv2.threshold(gray_roi, 155, 255, cv2.THRESH_BINARY)\n",
    "    inverted_img = cv2.bitwise_not(cropped)\n",
    "    aspect_ratio = inverted_img.shape[1] / inverted_img.shape[0]\n",
    "    # resize the image while keeping the aspect ratio\n",
    "    new_height = 20\n",
    "    new_width = int(new_height * aspect_ratio)\n",
    "    if new_width > new_height:\n",
    "        new_width = 20\n",
    "        aspect_ratio = inverted_img.shape[0] / inverted_img.shape[1]\n",
    "        new_height = int(new_width * aspect_ratio)\n",
    "    resized_img = cv2.resize(inverted_img, (new_width, new_height))\n",
    "    # pad the resized image with black pixels to make it 28x28\n",
    "    pad_width = (\n",
    "        ((28 - new_height) // 2, (28 - new_height + 1) // 2),  # no padding on top and bottom\n",
    "        ((28 - new_width) // 2, (28 - new_width + 1) // 2))  # pad equally on both sides to make the width 28\n",
    "    padded_img = np.pad(resized_img, pad_width, mode='constant', constant_values=0)\n",
    "    # img_brighter = cv2.add(inverted_img, 50)\n",
    "    normalized_img = (cv2.resize(padded_img, (28, 28)))\n",
    "#     cv2.imshow(\"preprocessed image\",normalized_img)\n",
    "#     cv2.waitKey(0)\n",
    "    img_tensor = convert_to_tensor(normalized_img)\n",
    "    print(f\"Img shape after: {img_tensor.shape}\")\n",
    "    cv2.destroyAllWindows()\n",
    "#     normalized_tensor = 2 * (img_tensor - img_tensor.min()) / (img_tensor.max() - img_tensor.min()) - 1\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "def keras_preprocessing(img):\n",
    "    RGB = 1\n",
    "    img = img.reshape(img.shape[0], img.shape[1], img.shape[2], RGB)\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_characters(img_name, model):\n",
    "    img = cv2.imread(img_name)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to get a binary image\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 9, 5)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.CHAIN_APPROX_SIMPLE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    fields_points_sorted = []\n",
    "    # Loop through the contours\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        threshold_value = 200\n",
    "        black_found = False\n",
    "        character = img[max((y + 3), 0):y + h - 3, max((x + 3), 0):x + w - 3]\n",
    "        # Iterate over all pixels and check if their intensity values are above the threshold\n",
    "        for row in range(character.shape[0]):\n",
    "            for col in range(character.shape[1]):\n",
    "                pixel_intensity = character[row, col]\n",
    "                if (pixel_intensity < threshold_value).any():\n",
    "                    black_found = True\n",
    "                    break\n",
    "            if black_found:\n",
    "                break\n",
    "        # Get the bounding rectangle of the contour\n",
    "        if 30 < w < 100 and 40 < h < 100 and black_found:\n",
    "            fields_points_sorted.append([max((y + 3), 0), y + h - 3, max((x + 3), 0), x + w - 3])\n",
    "            # cv2.imwrite(\"C:/Users/30698/Desktop/KULeuven/Capita Selecta/test.jpeg\", character)\n",
    "            # show_one_prediction(character,model)\n",
    "            #cv2.rectangle(img, (x + 3, y + 3), (x + w - 3, y + h - 3), (0, 255, 0), 2)\n",
    "    fields_points_sorted.sort(key=lambda r: r[2])\n",
    "    characters_sorted = []\n",
    "    for field_points in fields_points_sorted:\n",
    "        characters_sorted.append(img[field_points[0]:field_points[1], field_points[2]:field_points[3]])\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('image', characters_sorted[4])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return characters_sorted\n",
    "\n",
    "\n",
    "def show_one_prediction(img, model, i=0):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_inv = cv2.bitwise_not(gray)\n",
    "    _, binary = cv2.threshold(gray_inv, 25, 255, cv2.THRESH_BINARY)\n",
    "    # get the indices of the black pixels\n",
    "    y, x = np.nonzero(binary)\n",
    "\n",
    "    # get the maximum and minimum x and y coordinates\n",
    "    max_x = np.max(x)\n",
    "    min_x = np.min(x)\n",
    "    max_y = np.max(y)\n",
    "    min_y = np.min(y)\n",
    "    nonzero_indices = np.nonzero(binary)\n",
    "    darkened_gray = gray.astype('float32')\n",
    "    darkened_gray[nonzero_indices] *= 0.3\n",
    "    darkened_gray[not nonzero_indices] *= 1.1\n",
    "    darkened_gray = darkened_gray.astype('uint8')\n",
    "    cropped = darkened_gray[min_y:max_y, min_x:max_x]\n",
    "    cv2.imshow(\"bin\", cropped)\n",
    "    cv2.waitKey(0)\n",
    "    # _, thresh_img = cv2.threshold(gray_roi, 155, 255, cv2.THRESH_BINARY)\n",
    "    inverted_img = cv2.bitwise_not(cropped)\n",
    "    aspect_ratio = inverted_img.shape[1] / inverted_img.shape[0]\n",
    "\n",
    "    # resize the image while keeping the aspect ratio\n",
    "    new_height = 24\n",
    "    new_width = int(new_height * aspect_ratio)\n",
    "    if new_width > new_height:\n",
    "        return\n",
    "    resized_img = cv2.resize(inverted_img, (new_width, new_height))\n",
    "\n",
    "    # pad the resized image with black pixels to make it 28x28\n",
    "    pad_width = (\n",
    "        ((28 - new_height) // 2, (28 - new_height + 1) // 2),  # no padding on top and bottom\n",
    "        ((28 - new_width) // 2, (28 - new_width + 1) // 2))  # pad equally on both sides to make the width 28\n",
    "    padded_img = np.pad(resized_img, pad_width, mode='constant', constant_values=0)\n",
    "    # img_brighter = cv2.add(inverted_img, 50)\n",
    "    normalized_img = (cv2.resize(padded_img, (28, 28)))\n",
    "    # Turn off gradients to speed up this part\n",
    "    img_tensor = torch.from_numpy(normalized_img).unsqueeze(0)\n",
    "    normalized_tensor = 2 * (img_tensor - img_tensor.min()) / (img_tensor.max() - img_tensor.min()) - 1\n",
    "    # Define a transform to normalize the data\n",
    "    # Apply the transform to the tensor\n",
    "    print(normalized_tensor)\n",
    "    with torch.no_grad():\n",
    "        logps = model(normalized_tensor)\n",
    "\n",
    "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    # print((\"pred:\", probab.index(max(probab))))\n",
    "    # print((\"pred:\", ))\n",
    "    view_classify(img_tensor, ps)\n",
    "    cv2.imshow(\"actual\", img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "def view_classify(img, ps):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6, 9), ncols=2)\n",
    "    ax1.imshow(img.numpy().squeeze(), cmap='gray_r')\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [\n",
    "    ['MICHELLE', 'RODRIGUEZ', '12/02/1950', 'RFMR12025033445', 'DE1202507171'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['LAURA', 'MENDOZA', '16/10/1952', 'RFLM16105293143', 'BR1610522746'],\n",
    "    ['ANGELA', 'FITZGERALD', '04/07/1956', 'RFAF04075656622', 'BE0407563203'],\n",
    "    ['DAVID', 'LOPEZ', '17/01/1963', 'RFDL17016329220', 'BR1701638007'],\n",
    "    ['HECTOR', 'COOK', '09/02/1964', 'RFHC09026495520', 'IT0902647355'],\n",
    "    ['TIMOTHY', 'GREEN', '19/08/1968', 'RFTG19086827450', 'BR1908688556'],\n",
    "    ['ELIZABETH', 'RIVERA', '08/07/1970', 'RFER08077010123', 'BR0807708065'],\n",
    "    ['DEREK', 'CHURCH', '13/01/1972', 'RFDC13017297192', 'BL1301728110'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['KENNETH', 'STONE', '19/01/1977', 'RFKS19017711799', 'DE1901777829'],\n",
    "    ['EDWIN', 'ALLEN', '22/09/1977', 'RFEA22097775609', 'DE2209776709'],\n",
    "    ['ANGEL', 'SCHWARTZ', '18/05/1982', 'RFAS18058263146', 'BR1805822377'],\n",
    "    ['JARED', 'MURRAY', '26/01/1985', 'RFJM26018598155', 'BR2601853435'],\n",
    "    ['MELISSA', 'MENDOZA', '11/06/1987', 'RFMM11068724346', 'BL1106877773'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343']\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "true_labels=[\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['TIMOTHY', 'GREEN', '19/08/1968', 'RFTG19086827450', 'BR1908688556'],\n",
    "    ['LAURA', 'MENDOZA', '16/10/1952', 'RFLM16105293143', 'BR1610522746'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['ELIZABETH', 'RIVERA', '08/07/1970', 'RFER08077010123', 'BR0807708065'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['KENNETH', 'STONE', '19/01/1977', 'RFKS19017711799', 'DE1901777829'],\n",
    "    ['MICHELLE', 'RODRIGUEZ', '12/02/1950', 'RFMR12025033445', 'DE1202507171'],\n",
    "    ['DEREK', 'CHURCH', '13/01/1972', 'RFDC13017297192', 'BL1301728110'],\n",
    "    ['DAVID', 'LOPEZ', '17/01/1963', 'RFDL17016329220', 'BR1701638007'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['EDWIN', 'ALLEN', '22/09/1977', 'RFEA22097775609', 'DE2209776709'],\n",
    "    ['ELIZABETH', 'RIVERA', '08/07/1970', 'RFER08077010123', 'BR0807708065'],\n",
    "    ['MELISSA', 'MENDOZA', '11/06/1987', 'RFMM11068724346', 'BL1106877773'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['JAMES', 'HARRISON', '17/02/1990', 'RFJH17029026206', 'BE1702909215'],\n",
    "    ['ANGEL', 'SCHWARTZ', '18/05/1982', 'RFAS18058263146', 'BR1805822377'],\n",
    "    ['HECTOR', 'COOK', '09/02/1964', 'RFHC09026495520', 'IT0902647355'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['JARED', 'MURRAY', '26/01/1985', 'RFJM26018598155', 'BR2601853435'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793'],\n",
    "    ['HECTOR', 'COOK', '09/02/1964', 'RFHC09026495520', 'IT0902647355'],\n",
    "    ['SIERRA', 'YU', '29/03/1950', 'RFSY29035047838', 'IT2903504950'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['TIMOTHY', 'GREEN', '19/08/1968', 'RFTG19086827450', 'BR1908688556'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['LEAH', 'FERGUSON', '05/01/1976', 'RFLF05017691772', 'US0501769434'],\n",
    "    ['JEREMIAH', 'TUCKER', '11/10/1972', 'RFJT11107251133', 'BR1110727764'],\n",
    "    ['LAURA', 'MENDOZA', '16/10/1952', 'RFLM16105293143', 'BR1610522746'],\n",
    "    ['ANGELA', 'FITZGERALD', '04/07/1956', 'RFAF04075656622', 'BE0407563203'],\n",
    "    ['NICOLE', 'CANTU', '19/03/1989', 'RFNC19038962968', 'DE1903891767'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793'],\n",
    "    ['KENNETH', 'STONE', '19/01/1977', 'RFKS19017711799', 'DE1901777829'],\n",
    "    ['JARED', 'MURRAY', '26/01/1985', 'RFJM26018598155', 'BR2601853435'],\n",
    "    ['LORI', 'NUNEZ', '28/06/1997', 'RFLN28069748554', 'BR2806974343'],\n",
    "    ['JEFFREY', 'MOONEY', '19/04/1990', 'RFJM19049013684', 'BE1904901793']\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_date(model,characters_for_recognition,labels):\n",
    "    i=0\n",
    "    correct_fields=0\n",
    "    for char in labels:\n",
    "        if char != '/':\n",
    "            #model(characters_for_recognition[0])\n",
    "            # processed_input = extr.preprocess_pytorch(characters_for_recognition[i])\n",
    "            processed_input = preprocess_keras(characters_for_recognition[i])\n",
    "\n",
    "            # with torch.no_grad():\n",
    "            #     logps = model(processed_input)\n",
    "            # # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "            # ps = torch.exp(logps)\n",
    "            # probab = list(ps.numpy()[0])\n",
    "            # print(\"Predicted Digit =\", probab.index(max(probab)), \"\\tActual =\", char)\n",
    "            pred = label_dict_inv[np.argmax(model.predict(processed_input))]\n",
    "            print(f\"pred: {pred}\")\n",
    "            # if int(probab.index(max(probab))) == int(char):\n",
    "            if int(pred) == int(char):\n",
    "                correct_fields+=1\n",
    "        i += 1\n",
    "    return correct_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 16:43:02.222791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:02.225053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:02.225257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:02.225572: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-03 16:43:02.226158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:02.226275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:02.226374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:03.330468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:03.330623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:03.330749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-03 16:43:03.330853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1634 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# model_digits = LeNet()\n",
    "# model_digits.load_state_dict(torch.load('saved_models/digits_model_nn3'))\n",
    "model_digits = keras.models.load_model('./alphanum_model')\n",
    "\n",
    "print(\"Model successfully loaded\")\n",
    "\n",
    "# extract_characters('C:/Users/30698/Desktop/KULeuven/Capita Selecta/formes/fields/0001_DATE.jpg')\n",
    "# dir_path = 'C:/Users/30698/Desktop/KULeuven/Capita Selecta/formes/fields'\n",
    "dir_path = './Forms 24022023'\n",
    "\n",
    "# Define the allowed image extensions\n",
    "img_extensions = [\"DATE.jpg\", \"DATE.jpeg\", \"DATE.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 in ./Forms 24022023\n",
      "Checking for 0008.jpg:\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(dir_path):\n",
    "        # Iterate over all files in the current directory\n",
    "        correct=0\n",
    "        print(f\"Found {len(files)} in {dir_path}\")\n",
    "        for file in files:\n",
    "            # Check if the file has an image extension\n",
    "            print(f\"Checking for {file}:\")\n",
    "            \n",
    "#             if any(file.endswith(ext) for ext in img_extensions):\n",
    "                # Add the full path of the image to the list\n",
    "            img_path = os.path.join(root, file)\n",
    "            characters_of_date = extract_characters(img_path, model_digits)\n",
    "            print(len(characters_of_date))\n",
    "            file_index = int(file[:4])\n",
    "#             print(file_index)\n",
    "#             correct += predict_date(model_digits, characters_of_date, true_labels[file_index-1][2])\n",
    "#         print(\"Accuracy:\", correct/(44*8))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
